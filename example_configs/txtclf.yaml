general:
  task: 'nlp'
  subtask: 'txtclf'
  project_name: 'project_3'
  exp_name: 'experiment_1'

model:
#  model_type: 'lstm'
#  n_hidden: 128
  model_type: 'bert'
  model_name: 'bert-base-uncased'


data:
  dataset_folder: 'projects/datasets/imdb_dataset/'
  labels:
    - 'positive'
    - 'negative'
  lang: 'en'
  split: false
  train_len: 1000
  val_len: 200

cache_folder: 'embeddings/'
embeddings: 'en_glove-wiki-gigaword-50'

trainer:
  gpus: null
  max_epochs: 5

training:
  seed: 42
  batch_size_train: 8
  shuffle_train: True
  batch_size_val: 8
  shuffle_val: False
  workers: 0
  optimizer:
    name: 'Adam'
    params:
      lr: 0.0001
  criterion: 'CrossEntropyLoss'

checkpoint_callback:
  mode: max
  monitor: val_acc
  save_top_k: 1
  verbose: True
  filename: '{epoch}_{val_acc:.2f}'
