general:
  task: 'nlp'
  subtask: 'txtclf'
  project_name: 'project_3'
  exp_name: 'experiment_1'

data:
  dataset_folder: 'projects/datasets/imdb_dataset/'
  labels:
    - 'positive'
    - 'negative'
  lang: 'en'
  split: false
  train_len: 1000
  val_len: 200

# LSTM
#model:
#  model_type: 'lstm'
#  criterion: 'CrossEntropyLoss'
#  optimizer: 'Adam'
#  batch_size: 32
#  # TODO: change LR to 1e-5 form
#  lr: 0.0001
#  max_epochs: 100
#  n_hidden: 128
#  embeddings:
#    model: 'en_glove-wiki-gigaword-50'
#    cache_folder: 'embeddings/'

# BERT
model:
  model_type: 'bert'
  model_name: 'bert-base-uncased'
  criterion: 'CrossEntropyLoss'
  optimizer: 'Adam'
  batch_size: 32
  # TODO: change LR to 1e-5 form
  lr: 0.0001
  max_epochs: 100
  cache_folder: 'embeddings/bert/'

checkpoint_callback:
    mode: max
    monitor: val_acc
    save_top_k: 1
    verbose: True
    filename: '{epoch}_{val_acc:.2f}'